---
title: "A (Re-)Introduction to Linear Regression"
subtitle: "Digital and Social Media Strategies"
author: "Lachlan Deer"
institute: "Tilburg University"
date: "Updated: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, metropolis, metropolis-fonts]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: font160

# Learning Goals for this Week

* Interpret regression output from single- and multivariable linear regressions 
* Interpret linear regression coefficients from single- and multivariable linear regressions
* Explain why linear regression coefficients cannot always be interpreted causally
* Interpret linear regression estimates from the analysis of A/B tests

---
class: inverse, center, middle

# Simple Linear Regression: A Recap

---
# Example: Orange Juice

```{r, echo = FALSE, fig.align = "center", out.width="70%"}
url <- "https://parade.com/.image/t_share/MTkwNTgwODY0NjExMTk4MDc3/is-orange-juice-good-for-you-jpg.jpg"
knitr::include_graphics(url)
```

* Three Brands: Tropicana, Minute Maid and Dominicks 
* 83 Chicagoland Stores 
* Data on price, sales (quantity) and whether promoted
* Want to know the price elasticity of demand. How does this change when on promotion?

```{r, echo = FALSE, message = FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(broom)

oj <- read_csv("data/oj.csv")
```

---
# The Data: A Glimpse

```{r, echo = FALSE}
head(oj, n = 10)
```

---
# The Juice: Price, Brand and Sales 

.pull-left[
```{r, echo = FALSE}
oj %>%
  ggplot() +
  geom_boxplot(
    aes(x = brand, y = price, fill = brand)
  ) +
  theme_bw()
```
]

.pull-right[
```{r, echo = FALSE}
oj %>%
  ggplot() +
  geom_point(
    aes(x = log(sales/1e3), y = log(price), color = brand),
    alpha = 0.5
  ) +
  theme_bw()
```

]

**Each brand occupies a well defined price range. Sales decrease with price**

---
# Simple Linear Regression 

$$Sales_i = \beta_0 + \beta_1 price_i + \varepsilon_i$$

```{r, echo = FALSE}
summary(lm(sales/1e3 ~ price, data = oj))
```

**In class activity:** explain this output & interpret coefficients

---
# Logarithmic Transformations I

$$\log(Sales)_i = \beta_0 + \beta_1 price_i + \varepsilon_i$$


```{r, echo = FALSE}
tidy(lm(log(sales) ~ price, data = oj))
```

**Coefficient Interpretation** (in general): 

On average, a change in X by one unit, $\Delta X=1$, is associated with a $(\exp(\beta_1) - 1)*100$ % change in Y

* Remark: for small $\beta_1$, $(\exp(\beta_1) - 1) \approx \beta_1$ so often you will see an interpretation that reads straight from $\beta_1$ 

**Coefficient Interpretation** (this example): 


---
# Logarithmic Transformations II

$$Sales_i = \beta_0 + \beta_1 \log(price_i) + \varepsilon_i$$

```{r, echo = FALSE}
tidy(lm(sales/1e3 ~ log(price), data = oj))
```

**Coefficient Interpretation** (in general): 

On average, a 1% change in X is associated with a change in Y of $0.01 \times \beta_1$

**Coefficient Interpretation** (this example): 


---
# Logarithmic Transformations III

$$\log(Sales)_i = \beta_0 + \beta_1 \log(price_i) + \varepsilon_i$$

Remark: Sales in 000s.

```{r, echo = FALSE}
tidy(lm(log(sales) ~ log(price), data = oj))
```

**Coefficient Interpretation** (in general): 

On average, a 1% change in X is associated with a change in $\beta_1$ % change in Y 
  * $\beta_1$ is the elasticity of Y with respect to X

**Coefficient Interpretation** (this example): 

---
class: inverse, center, middle
# Multivariable Regression 

---
# Multivariable Regression: One Control

$$Sales_i = \beta_0 + \beta_1 price_i + \beta_2 \text{promotion}_i + \varepsilon_i$$


```{r, echo = FALSE}
summary(lm(sales ~ price + feat, data = oj))
```

---
# Multivariable Regression: One Control II

$$\log(Sales)_i = \beta_0 + \beta_1 \log(price_i) + \beta_2 \text{On Promotion}_i + \varepsilon_i$$

```{r, echo = FALSE}
summary(lm(log(sales) ~ log(price) + feat, data = oj))
```

---
# Multivariable Regression: Many Controls

$$
\begin{aligned}
\log(Sales)_i = \beta_0 &+ \beta_1 \log(price_i) + \beta_2 \text{On Promotion}_i + \\ 
                        &\beta_3 \text{Tropicana}_i  + \beta_4 \text{Minute Maid}_i + \varepsilon_i
\end{aligned}
$$

```{r, echo = FALSE}
summary(lm(log(sales) ~ log(price) + feat + brand, data = oj))
```

---
# Interaction Effects 

Beyond additive effects: **variables change how others act on $y$**

An **interaction term** is the product of two covariates:

$$y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \beta_{2k} x_{i2} \times x_{ik} + \varepsilon_i$$

So that the effect on $y$ of a unit increase in $x_2$ is:

$\beta_2 + \beta_{2k}x_{ik}$

$\implies$ **it depends on $x_k$**

Example: How do promotions affect price sensitivity?

---
# Interaction Effects

```{r, echo = FALSE}
tidy(lm(log(sales) ~ log(price)*feat + brand, data = oj))
```

---
# Interpreting Interaction Effects

$$
\begin{aligned}
\log(Sales)_i = \beta_0 &+ \beta_1 \log(price_i) + \beta_2 \text{On Promotion}_i \\
                        &+ \beta_3 (\text{On Promotion}_i \times \log(price_i)) + \varepsilon_i
\end{aligned}
$$

We observe: 

* $\hat{\beta}_1$ = -2.34
* $\hat{\beta}_3$ = -0.88

$\implies$

* Price elasticity when **not** on sale: $\beta_2$ -2.34
* Price elasticity when on sale: $\beta_2 + \beta_3$ -3.22

On average, promotions make consumers more / less on price sensitive

Does this make sense? Why?

(In class discussion)

---
class: font160
# Regression and Causality

.center[Regression assumptions on their own] 

$$
\neq \quad \text{ causal interpretations of } \beta
$$

* **Regression assumptions**: Unbiasedness, Variance of estimates 
* "**Causal Inference assumptions**": Can an unbiased estimate be interpreted causally? Yes if ...
  1. No sample selection bias
  2. "No lurking variables"
  3. Valid counterfactual outcome to make comparisons

Note: Cannot test these assumptions 'statistically'

---
class: inverse, center, middle

# Linear Regression in A/B Tests

---
class: font120
# Fast Food Promotions Redux 

```{r, echo = FALSE, fig.align = "center", out.width="80%"}
url <- "https://cdn.vox-cdn.com/thumbor/4mAGUkdlOUBL_INj2X2uZ53BR8U=/0x0:1100x825/1200x800/filters:focal(0x0:1100x825)/cdn.vox-cdn.com/uploads/chorus_image/image/46157824/american-burgers.0.0.jpg"
knitr::include_graphics(url)
```

* New fast food item introduced to all stores 
* Three different promotions used, managers care about sales 
* Promotions randomly allocated to stores
* Different promotion strategies may have different effectiveness  

```{r, echo = FALSE, message = FALSE}
library(readr)
library(dplyr)
library(janitor)

all_data <- read_csv("data/WA_Marketing-Campaign.csv") %>%
  clean_names() 

two_promotion <- 
  all_data %>%
  filter(promotion != 3)
```

---
class: font140
# Causal Interpretations and Experiments 

**Regression estimates from analysis of experiments have causal interpretations**

Why? 

* Counterfactual outcomes - compare to an alternative promotion
* "As good as random" assignment to treatments - lurking variables won't trouble us 
* No sample selection bias ... analyst picked the sample to match the group they care about
  
Regression estimates from experiments allow us to:

* Test whether treatments have effects 
  * Same as ANOVA or a t-test
* Estimate a magnitude of the effect sizes (and standard errors)
  * Which our t-test and ANOVA didn't

---
class: font140
# Two Promotion Comparison 

$$\text{Sales}_i = \beta_0 + \beta_1 \text{Promotion Type 2} + \varepsilon_i$$

```{r, echo = FALSE}
simple_reg <- lm(sales_in_thousands ~ as.factor(promotion), data = two_promotion)
summary(simple_reg)
```

---
class: font140
# Two Promotion Comparison 

In class questions:

* Why only an estimate of promotion 2 and not also promotion 1?
* How to interpret this regression?

**Answers:** 

* When a constant is included in the regression 1 categorical variable must be left out ...
  - We have two categories since we have two treatments (promotion 1 and promotion 2)

* $\beta_0$ is the average revenue for stores who were in Promotion 1
* $\beta_0 + \beta1$ is the average revenue for stores who were in Promotion 2

$\implies$ $\beta_1$ is the average difference in revenue (in 000s) between promotion 2 and promotion 1

---
# Two Promotion Comparison with log Y

$$log(\text{Sales}_i) = \beta_0 + \beta_1 \text{Promotion Type 2} + \varepsilon_i$$

```{r, echo = FALSE}
simple_reg <- lm(log(sales_in_thousands) ~ as.factor(promotion), data = two_promotion)
summary(simple_reg)
```

---
class: font140
# Two Promotion Comparison with log Y

In class questions:

* How to interpret this regression?
* Could we also take the log of the X variable?

**Answers**:

* $\beta_0$ is the average log revenue for stores in promotion 1. Not very useful ...
* $\beta$ is (approximately) the average percentage difference in revenue between promotion 2 and promotion 1. 
  * $\exp{\hat{\beta_1}} - 1$ is the exact percentage difference...
* We cannot take the log of `Promotion 2`. This variable is either zero (not in promotion 2) or 1 (in promotion 1)
  - ... And log(0) is not defined
  - ... Thats OK, the interpretation is still nice!

---
# Three Promotion Comparison 

$$\text{Sales}_i = \beta_0 + \beta_1 \text{Promotion Type 2} + \beta_2 \text{Promotion Type 3} + \varepsilon_i$$

```{r, echo = FALSE}
full_reg <- lm(sales_in_thousands ~ as.factor(promotion), data = all_data)
summary(full_reg)
```

---
class: font140
# Three Promotion Comparison 

In class questions:

* Why only an estimate of promotion 2 and 3 and not also promotion 1?
* How to interpret this regression?

**Answers**: 

* Now have three categories, Promotion 1, Promotion 2, Promotion 3. Can only estimate two effects since $\beta_0$ captures the average of outcome variable for left out group.
* $\beta_0$ is the average revenue for stores in Promotion 1
* $\beta_1$ is the average difference in revenue for stores in Promotion 2 compared to Promotion 1.
* $\beta_2$ is the average difference in revenue for stores in Promotion 3 compared to Promotion 1.
* $\beta_3 - \beta_2$ is the average difference in revenue between stores in Promotion 3 compared to Promotion 2.


---
# Three Promotion Comparison


$$\log(\text{Sales}_i) = \beta_0 + \beta_1 \text{Promotion Type 2} + \beta_2 \text{Promotion Type 3} + \varepsilon_i$$

```{r, echo = FALSE}
full_reg <- lm(log(sales_in_thousands) ~ as.factor(promotion), data = all_data)
summary(full_reg)
```

---
class: font140
# Three Promotion Comparison with Log Y

In class questions:

* How to interpret this regression?

**Answers:**

* $\beta_0$ is the average log revenue for stores in Promotion 1
* $\beta_1$ is the average percentage difference in revenue for stores in Promotion 2 compared to Promotion 1.
* $\beta_2$ is the average percentage difference in revenue for stores in Promotion 3 compared to Promotion 1.
* $\beta_3 - \beta_2$ is the average percentage difference in revenue between stores in Promotion 3 compared to Promotion 2.

---
class: inverse, center, middle

# Recap

---
class: font160
# Recap

* Simple Linear Regression estimates the association between an outcome variable and a dependent variable 
* Multiple Linear Regression estimates the association between an outcome variable and multiple dependent variable
* Regression estimates do not always have a causal interpretation 
* Can use linear regression to estimate the effects of treatments on an outcome variable in an A/B test (experiment) setup
* Linear regression estimates from A/B tests allow us to test for statistically significant differences across treatments ...
* ... *and* provide estimate of the effect sizes across treatments

---
# License & Citation

Suggested Citation:

```{r, engine='out', eval = FALSE}
@misc{deerdsms2022,
      title={"Digital and Social Media Strategies: A (Re-)Introduction to Linear Regression"},
      author={Lachlan Deer},
      year={2022},
      url = "https://github.com/tisem-digital-marketing/dsms-lecture-03-regression"
}
```

<p style="text-align:center;"><img src="https://www.tilburguniversity.edu/sites/default/files/styles/large_width/public/image/Logo%20OSCT.png?itok=PqU9mw_l" alt="Logo" width = "200"></p>

This course adheres to the principles of the Open Science Community of Tilburg University. 
This initiative advocates for transparency and accessibility in research and teaching to all levels of society and thus creating more accountability and impact.

<p style="text-align:center;"><img src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" alt="Logo" width = "100"></p>
This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.